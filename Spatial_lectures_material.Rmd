---
title: "R Data Science: Spatial Data Science 1"
author: "steppe"
date: "1/6/2022"
output:
   pdf_document:
      fig_caption: true
      number_sections: true
      includes:
        in_header: float_free.tex
---

\tableofcontents 
\listoffigures
\listoftables

Assigned Reading: Geocomputation with R Chapter 2.

# Example Data

## Libraries

```{r Load Libraries, message = F, warning = F, echo = F}
shhh <- suppressPackageStartupMessages 

shhh(library(sp))
shhh(library(sf))
shhh(library(raster))
shhh(library(tidyverse))
shhh(library(terra))
shhh(library(sloop)) # for objects

rm(shhh)
```

## Example Data Methods 

I used the United States Geological Surveys 'Earth Explorer' to view images taken from the Sentinel 2 Satellite over the last year at a location on the border of California and Nevada near Reno. I downloaded several images which both A) covered the area of analysis well, and B) did not have much cloud cover. I used the Open Source QGIS, which has a graphical user interface (GUI), to manually geo-reference the images to locations on the earths surface. I then manually marked the edges of bodies of water, and created polygons which cover them. These data were saved as polygon vector files, in a format know as a 'shapefile' and imported them to R. 

These steps can all be done programmatically, but I only wanted a few good images, so went through the process by hand. 

Here we import our vector data, immediately create a 'Simple Feature' object, and add some attributes regarding the data
```{r import Vector Data, echo = F}
# getwd()
path <- './spatial_lecture_data/sentinel_imagery'
files.shp <- list.files(path, ".shp")

dec_lakes_v <- read_sf(paste0(path,"/",files.shp), quiet = T) %>% 
  mutate(Data_source = 'Sentinel2') %>% 
  mutate(Processing = 'DL from Earth Explorer, manually georeferenced, and mapped') %>% 
  mutate(Date = as.POSIXct('2021/12/05', '%Y/%m/%d', tz = "US/Pacific-New"))

st_precision(dec_lakes_v) <- 50 # note I am saying each of the points I drew were within 50 meters of the true location. This is not important but I populate for an example below. We are in meters because we are in UTM. 

oct_lakes_v <- dec_lakes_v %>% filter(id %in% c(1,2,3,5,6,12)) %>% 
  mutate(Date = as.POSIXct('2021/10/16', '%Y/%m/%d', tz = "US/Pacific-New"))# gui's are confusing. 
# these bodies of water were not present in the earlier time period, but I am too stupid to make the GUI work and so remove them programmatically.

rm(files.shp, oct_lakes_v)
```

We import the Sentinel 2 images here. We will use them as a template to create a raster. 
```{r import Raster data, echo = F, warning = F, message = F}

files.tif <- list.files(path, ".tif")
dec_lakes_r <- raster(paste0(path,"/",files.tif[1]), )
oct_lakes_r <- raster(paste0(path,"/",files.tif[3]))

#crs(dec_lakes_r)
#newproj <- CRS("+proj=utm +zone=10 +datum=WGS84")
#dec_lakes_r <- projectRaster(dec_lakes_r, crs=newproj)


rm(files.tif, path)
```

We will very quickly reclassify the input images to populate our new example rasters with data. 
```{r Quickly Reclassify Rasters for an example, echo = F}
reclass_first <- matrix(
  c(0, 1, NA,
    1 ,50, 0,
  50, 250, 1),
        nrow = 3, 
        ncol = 3,
       byrow = T) 

dec_lakes_r_classified_c <- reclassify(dec_lakes_r, reclass_first)
oct_lakes_r_classified_c <- reclassify(oct_lakes_r, reclass_first)

#plot(dec_lakes_r_classified_c) # check this has an intermediate 
# step we will be able to remove some of
#barplot(dec_lakes_r_classified_c,
#        main = "Number of pixels in each class")

dec_lakes_r_classified_f <- aggregate(dec_lakes_r_classified_c, 7.0)
oct_lakes_r_classified_f <- aggregate(oct_lakes_r_classified_c, 7.0)

reclass_second <- matrix(
  c(0, 0.5, 0,
    0.5, 1, 1),
        nrow = 2, 
        ncol = 3,
       byrow = T)

dec_lakes_r_classified_f <- reclassify(dec_lakes_r_classified_f, reclass_second)
oct_lakes_r_classified_f <- reclassify(oct_lakes_r_classified_f, reclass_second)

rm(reclass_first, reclass_second, dec_lakes_r_classified_c, oct_lakes_r_classified_c, oct_lakes_r)

```


```{r Define some raster helper functions, echo = F}
cell_count <- function(x){
  obj_name <- deparse(substitute(x))
  writeLines(paste0('This ', obj_name, ' contains: ', nrow(x) * ncol(x), ' elements'))
}

resolution_of_raster <- function(x){
  writeLines(paste0('The width of each raster cell is: ',
               round((x@extent@xmax - x@extent@xmin)/x@ncols, 5),
               ' meters'))
  writeLines(paste0('The height of each raster cell is: ',
               round((x@extent@ymax - x@extent@ymin)/x@nrows, 5),
               ' meters'))
}

```


We will create empty example rasters. 
```{r Create Empty Raster and Populate, echo = F, comment = ""}

ext_rast <- st_bbox(dec_lakes_r)
grid <- st_make_grid(ext_rast,  # create a fishnet to emulate the idea of an empty raster ! :-)
  n = c(118, 118),
  what = "polygons",
  square = TRUE,
  flat_topped = FALSE)
# st_write(grid, 'Example_HoneyLake_Grid.shp')

empty_raster <- raster(
  # A raster is composed of four perpendicular lines.
  # Here we define each 'edge' of the raster'
                         xmn = 697129.7, 
                         xmx = 811775.7, 
                         ymn = 4388466,
                         ymx = 4502382,
                         
                         nrows = 118, # we are creating 100 cells.  
                         ncols = 118, # We can calculate the resolution of these below.
                         
                         crs = "+proj=utm +zone=10 +datum=WGS84", 
                         # set the rasters Coordinate Reference System
                         )

rast_vals_num <- as.integer(as.vector(as.numeric(dec_lakes_r_classified_f@data@values)))

raster_matrix <- matrix(rast_vals_num, # fill matrix with values, 
                       nrow = empty_raster@nrows, # create matrix same dimensions as raster
                       ncol = empty_raster@ncols, # create matrix same dimensions as raster
                       byrow = T) #ensure filling of matrix goes from upper left to lower right.

example_raster_dec <- setValues(empty_raster, raster_matrix)
example_raster_oct <- setValues(empty_raster, oct_lakes_r_classified_f@data@values )
# plot(example_raster_dec)
# plot(example_raster_oct)

fake_data <- matrix(c(0,1,1,0,1,0),
                    nrow = 6,
                    ncol = 8,
                    byrow=T)

rm(fake_data, ext_rast, grid)
```

# What is a Geographic Information System?

## What is a GIS

- **G**eographic **I**nformation **S**ystem is a system for producing, managing, displaying, and analyzing geographic information.
- Spatial Data Science is an emergent field which utilizes data science approaches in a **GIS**, and is a natural extension of a **GIS**

When we think about it, nearly all data has a spatial dimension, it just tends to be ignored in much of science. Historically this is sensible as performing these analysis is computationally expensive, and requires considerable expertise. 


```{r, out.width = "35%", fig.show='hold', echo = F, fig.align="center", fig.cap = "A Visualization of a GIS, by Anne Sexton"}
knitr::include_graphics("./pictures/USGS_GIS_Anne_Sexton.jpg")
```

This is I think really one of the best and simplest way's of showcasing at heart what a GIS is. A GIS is a system wherein we can explore and study the relationships of different attributes on a process in a spatial context.

## A Brief History

- Dr. John Snow suspected Cholera was spread by water
- 1854 outbreak of Cholera in the Soho neighborhood of London kills 616 persons
- Snow used both *mapping* and *statistics* to identify the water source and stop the outbreak.
- Essentially founded both Epidemiology and GIS in one stroke

```{r, out.width = "35%", fig.show='hold', echo = F, fig.align="center", fig.cap = "The Broad Street Pump, A Cholera Outbreak in London, By: John Snow and digitized by National Geographic"}
knitr::include_graphics("./pictures/John_Snow_Cholera_by_National_Geographic.jpg")
```

A good article with a quote by Tufte, anXKCD, and meaningful insight by a journalist at the Guardien is below:

https://www.theguardian.com/news/datablog/2013/mar/15/john-snow-cholera-map

- Since then GIS has continually made more use of computers and come to be it's own discipline as computers have become more available. 

## What is Spatial Data Science?

- The application of Geographic insights, and geospatial analyses to big data sets
- Including spatial terms in statistical models
- Bringing Geographic information to data science questions
- Developing your own spatial products and pipelines

## Why Use R as a GIS and for Spatial Data Science ?

- Work Flow Automation
- Rich Ecosystem (packages, functions, code-sharing, etc.)
- Reproducible
- Self Documenting
- Computationally Efficient
- Parallel Processing/HPC interfaces

There is a great range of computer Geographic Information Systems to choose from. Many of you are likely to be familiar with a software program call 'ArcGIS' and to a lesser extent 'ArcMap' produced by the ESRI company. These products are widely used in nearly all branches of the federal and many state governments, as well as at many large companies especially environmental consultants. I think that this is a good system for you to learn about geospatial operations and workflows in, but nearly all of the work that can be accomlished in ESRI products can be accomplished in R. If you go into several environmental fields, you will need to learn to interface with ESRI products. I advise you to familiarize  yourself with them.

On the other hand, I encourage you all to use R as the central piece of your geospatial analysis. If you are not developing new spatial products, you can run all of your analyses in R. If you are interested in making maps - cartography, R is now quite capable for making publication quality maps, as well as for reports and projects. It does lack slightly in cartography aspects, but you can create the data you want to style in another software, such as the open source QGIS, here and export it. But as we will see, cartography is not equivalent to GIS, and GIS is not equivalent with  cartography. Do not expect to be able to make *National Georgraphic* quality maps no matter which GIS you use. 

If you are very interested in geospatial work than you will see that you use a number of software programs to perform your research. In most cases you will still keep R as the centerpiece, but will likely work within a Linux environment and make good use of Unix and Bash scripts, Python, and QGIS to help fill in some parts of work-flows which R cannot address as well. You will find that R, Python, and QGIS all use many of the same software components and libraries such as GDAL/OGR, GEOS, PROJ, GRASS GIS, which have been developed by the Open Source Geospatial Foundation which was actually founded in Chicago around 20 years ago. 

We will draw heavily from the Open Source Geospatial Foundation in these lectures.

# Geodesy 

- 'Geodesy is the science of accurately measuring and understanding the Earth's geometric shape, orientation in space, and gravity field.' - NOAA

This is a very highly specialized field, of which I have no formal training in when it comes to the theory of it. I do believe we have a couple specialists in Earth and Planetary Sciences, but I am far from them. Here I will cover the most basic facets of this field as they pertain to geospatial analysis among non-specialists. A more apt title for this section could be *'Geodesy taught by a dummy'*

## Earth is not a **perfect** sphere

- Circumference at equator:	40,075 km (24,901 mi)
- Circumference along meridians: 40,009 km (24,860 mi)

Earth is not a sphere; it is ever so slightly longer than wide. The earth is actually around 43 km/27miles wider at the equator. Note the average radius of the earth is around 6371 km/3959 mi so this is quite small! However, trying to represent the Earth as a perfect sphere in geospatial models will lead to inaccurate representation of the location of objects on it.

```{r, out.width = "35%", fig.show='hold', echo = F, fig.align="center", fig.cap = "Blue Marble 2012, by Suomi NPP", fig.asp=0.50}
knitr::include_graphics('./pictures/NASA_Blue-Marble_2012_Suomi_NPP.jpg')
```

### The Earth can be represented as an Ellipsoid

- A simple 3d geometric shape
- An ellipsoid is a slightly to greatly ovaliform shape
- Modeling the Earth as an ellipsoid increases the accuracy of point locations

Because the earth is slightly wider than long, the earth is technically and can be modeled practically as an ellipsoid. This model of representing the earth assumes no terms of gravity, winds, or tides. I.e. it is a perfect geometric shape with bilateral symmetry. 

You can imagine that there are certain limitations to the accuracy of our model of the earth without including gravity.

```{r, out.width = "50%", fig.show='hold', echo = F, fig.align="center", fig.cap = "Ellipsoids", fig.asp=0.50}
knitr::include_graphics('./pictures/Spheroids.png')
```

### However, the Earth's surface is not smooth - Geoid

- Types of models to represent planet Earth
- Include gravity, excluding winds and tides
- Highly accurate since application of GPS technology

The Earth can also be represented as a geoid, which is a model of earth still lacking the effects of wind and tides on the earth – but which includes the major force - gravity. Because the effect of gravity is retained, the earths overall shape is both elliptical however the surface is irregular in regard to distance from the center. The surface of the Geoid is oftentimes roughly equivalent to what we could call a global mean sea level.

```{r, out.width = "35%", fig.show='hold', echo = F, fig.align="center", fig.cap = "Left: Geoid Cross Section. Right: IGCM Geoid"}
knitr::include_graphics('./pictures/geoid_cross_section.png')
knitr::include_graphics('./pictures/Geoid_undulation_10k_ICGEM.jpg')
```

Oftentimes now, very finely resolved geoids are combined with satellite measurements, and these observations are then fit with ellipsoid models, which we then use as our models of the earths surface.

By International Centre for Global Earth Models (ICGEM) - http://icgem.gfz-potsdam.de/vis3d/longtime / Ince, E. S., Barthelmes, F., Reißland, S., Elger, K., Förste, C., Flechtner, F., Schuh, H. (2019): ICGEM – 15 years of successful collection and distribution of global gravitational models, associated services and future plans. - Earth System Science Data, 11, pp. 647-674,DOI: http://doi.org/10.5194/essd-11-647-2019., CC BY 4.0, https://commons.wikimedia.org/w/index.php?curid=81462823

## Geodetic Datums

- Reference frame established to represent locations within the frame. 
- Historically these were locally focused and based on Geoids. 
- A datum can serve either horizontal (X & Y) or vertical (Z) features. 

- Components:
    - reference ellipsoid or geoid
    - origin point (from which measurements run)
    - control points very strictly measured from the origin, 
  
Other locations are then measured from in relation to the control points. 

```{r, out.width = "50%", fig.show='hold', echo = F, fig.align="center", fig.cap = "Number one City Datum. by: Cosmo1976", fig.asp=0.50}
knitr::include_graphics("./pictures/Number_One_City_Datum_Cosmo1976.jpg")
```
When we think of the Origins of datum points, the Equator and Prime Meridian are the most famous. However, there have been a great many datums in history. 

```{r Map of Chicago Datum, fig.align="center", fig.cap = "Control Points Number one City Datum", out.width = "75%", echo = F}
chicago_cntrl_pts <- read_sf('./spatial_lecture_data/Elevation_Benchmarks.csv')[c(1:4,8:12)] %>% 
  st_as_sf(coords = c(y = 'LONGITUDE', x = 'LATITUDE'), crs = 4326) %>% 
  janitor::clean_names() %>% 
  mutate(elevation = as.numeric(elevation))

origin_point <- chicago_cntrl_pts %>% 
  filter(benchmark_number == 1)

files <- paste0('./spatial_lecture_data/Chicago_Neighborhoods/' , 
                list.files('./spatial_lecture_data/Chicago_Neighborhoods', ".shp"))
chicago_nghbrh <- read_sf(files)

ggplot() +
  geom_sf(data = chicago_nghbrh, alpha = 0.4) +
  geom_sf(data = chicago_cntrl_pts, aes(color = elevation)) +
  geom_sf(data = origin_point, shape = 8, size = 3, color = "red") +
  labs(title = 'Control Points for Number One City Datum') +
  theme_linedraw() +
  theme(plot.title = element_text(hjust = 0.5), 
        legend.position = c(0.001, 0.001), legend.justification = c(0, 0), 
        legend.box.background = element_rect(color="black", size=1), 
        legend.box.margin = margin(0, 0, 4, 0))

rm(chicago_cntrl_pts, files, chicago_nghbrh, origin_point)
```

In fact the city of Chicago established it's own elevation datum in the late 1920's. If we look at this quick map, we can see where the Origin point (also pictured) and control points are located.

Also do you really think Chicago is only 80 feet at most above sea level? No of course not! The lowest elvations in the city are roughly 580 feet above sea level, but in the 1920's, it was much easier to define elevation from an adjacent location. So all the values in the map should be X + ~580 ! This is exactly why so many datums are out there. 

### Geodetic Coordinatees

Since our area is 3-dimensional, we use a system related to Cartesian coordinates, however given the curve of the earths surface curvilinear rather than linear coordinates are used.

"The geodetic (or geographic) latitude is the angle between the equatorial plane and the normal (vertical) to the ellipsoid surface at the considered point." - Proj

- phi = geodetic latitude (north/south)
- lambda =longitude (east/west)
- *h* = ellipsoidal height 
- N = Normal (A plane at a right angle to the surface of the ellipsoid)

In the sphere image we have a latitude of 40*, but we do not know to which hemisphere it is associated with. 

```{r, out.width = "25%", fig.show='hold', fig.align="center", echo = F, fig.cap = "Angles on Ellipsoid and Geodetic Coordinates. by: Peter Mercator"}
knitr::include_graphics("pictures/Geodetic_Coordinates1_Peter_Mercator.png")
knitr::include_graphics("pictures/geodetic_coordinates_Peter_Mercator.png")
```

By Peter Mercator - Own work, CC BY-SA 3.0,  https://commons.wikimedia.org/w/index.php?curid=17717979

### Coordinate Notation

- Trigonometric
  - Degrees Minutes Seconds (DMS), e.g. 42°03'27.7" N
    - Sexagesimal/base 60 (think: minutes in an hour) 
  - Decimal Degrees (DD), e.g. 42.05759 N
    - Decimal Fractions of a Degree (portion of 360/2)
    
- DMS; seldom used in digital formats
- DD; almost exclusively used
  

Recorded in many forms DMS, DD, (trigonometry) UTM.

As a circle has 360 degrees, so does the earth. Given the nature of datums we split the world into a positive and negative sign for both latitude and longitude; we refer to the 0 lines as '0 meridians'. We have 180 positive and 180 negative degrees, and as these are of a course resolution we retain the decimals of degrees to better locate objects. As you all know, the Western Hemisphere is the negative component of a 180 degree half.  


$$
\text{Decimal Degrees} = \text{Degrees } + \frac{\text{Minutes}}{60} + \frac{\text{Seconds}}{3600} 
$$
$$
\text{Latitude of Tech} =  42°03'27.7" N
$$

$$
42 + (\frac{03'}{60}) + (\frac{27.7"}{3600})
$$

$$
42 + 0.05 + 0.007694 = 42.05759 \text{ Decimal Degrees}
$$

- Universal Transverse Mercator (UTM)
  - Divides the world into 60 zones
  - Flattens each zone
  - Measures distances in Meters
  
UTM - Common for field work, planar measurements of meters. 

```{r UTM Zones of the Continental USA, echo = F, message = F, warning=F}

utm_grid <- read_sf('./spatial_lecture_data/World_UTM_Grid/0f893164-d038-48ff-98dd-9fefb26127d3202034-1-145zfwr.nwf1.shp') %>% 
  filter(ZONE > 9 & ZONE < 20) %>% 
  filter(ROW_ %in% LETTERS[18:21]) %>% 
  group_by(ZONE) %>% 
  summarize(geometry = st_union(geometry))

bound <- st_bbox(utm_grid)
bound <- c(bound[1]+2,
            bound[2]+2,
            bound[3]-2,
            bound[4]-2)

world <- st_read(system.file("shapes/world.gpkg", package="spData"), quiet = T)

ggplot(utm_grid) +
  geom_sf(data = world) +
  geom_sf(fill = NA, color = "black") +
  geom_sf_label(aes(label = ZONE)) +
  theme_classic() +
  labs(title="UTM Zones of the Continental USA") +
  coord_sf(xlim = c(bound[1],bound[3]), ylim = c(bound[2],bound[4])) +
  theme(plot.title = element_text(hjust = 0.5))

rm(utm_grid, bound, world)
```

## Coordinate Reference System

The comprehensive system of specifying locations on the Earth's surface. Each Coordinate Reference System is composed of an Ellipsoid (or Geoid), a geodetic datum, and for cartographic purposes a projection.

```{r, out.width = "40%", fig.align="center", fig.show='hold', echo = F, fig.cap = "Geographic_Coordinate_Reference_System. by: Anna Krystalli"}
knitr::include_graphics("pictures/Geographic_Coordinate_Reference_System.jpg")
```

## Problems with working on flat surfaces

3D to 2d does not work well. But we have worked around this. **sorta**

```{r, out.width = "50%", fig.align="center", fig.show='hold', echo = F, fig.cap = "Orange Peel. by: Nathan Belz"}
knitr::include_graphics("pictures/Orange_peel_Nathan_Belz.png")
```

### Geographic Coordinate System 

- Three dimensional locations on Earths Surface

Where the location is on located earth. We are able to pinpoint locations, quite easily using one of the Global Navigation Satellite Systems, for example the 'Global Positioning System' or GPS. We have a coordinate system for this known as the World Geographic Datum. As we are merely recording the location of an object on a 3d object this is now essentially a trivial process. 

### Projected Coordinate System 

Most of us work on flat desks and flat computer screens. We need to represent locations in space on these surfaces. We project coordinates from their geographic locations on earth to locations on flat representations of earth.

### Major Map Projections

Many different ways to create two dimensional maps – thousands of projections. None are perfect. There are four main types of projections, each with their own strengths and examples. One of the most common examples of each of these is included in the table below. 

- Equal Area: Lambert Cylindrical equal-area
  - Pro: No distortion of area near equator (here)
  - Con: Distorts area at the Polar regions
- Equal Distance: Equi-rectangular (plate carrée projection)
  - Pro: Looks good in mapping applications
  - Con: Distorts both shape and directions
- Conformal: 
  - Pro: Boundaries are accurate
  - Con: Distorts Polar area
- Compromise: 
  - Pro: Sensitive to both area and direction
  - Con: Sensitive to both area and direction

```{r, out.width = "75%", fig.align="center", fig.show='hold', echo = F, fig.cap = "Map Projections. by: Daniel Strebe"}
knitr::include_graphics("./pictures/Projection_Maps.png" )
```

## Geodesy Takeaways

Unless you really focus on GIS, hardly anything I have said this lecture will matter to you.

- There are various models (geoids & ellipsoids) to represent the shape of the earth
- Different datums are used to represent different parts of the earth. This is in part due to legacy effects. 
- You will almost always use WGS 84 (based on a ellipsoid – which is fit through a special model of earths gravitational fields a geoid) NAD83 (based on a ellipsoid) for a geographic coordinate system.  These +/-1 m from each other across much of North America. More useful than a geoid.
- You will usually want to use a UTM grid  based on WGS for or State Planes based on NAD83 for projections.
- Different coordinates notation systems are used, focus on Decimal degrees. 

# An Introduction to Geographic Data Models

- **Vector Data Model** represents discrete features on the planet using geometries such as: points, lines, and polygons. 
- **Raster Data Model** represents (usually) continuous features on the plant using continuous surfaces, like a tile. 

Vector data tends to only include features of interest, e.g. bodies of water; whereas a Raster will include, **explicitly**, the absence of features (e.g. both water and terrestrial areas).


```{r, out.width = "85%", fig.align="center", fig.show='hold', echo = F, fig.cap = "Vector and Raster Data Models"}
knitr::include_graphics("./pictures/vector_raster.png")
```

Talking:

In our field, we generally take values from rasters to serve as predictors to our sample unit, many of us store our sample as spatial points. We also tend to predict our models back onto raster surfaces.

# R Data Types Reviewed

Remember that different data types take up different amounts of memory in pretty much all software systems. 

```{r Larger Data Set Integer vs Numeric, echo = F, comment = "", warning = F, message = F}
numeric_vals <- round(rnorm(n = 10000000, mean = 25, sd = 5), 4)
int_vals <- as.integer(numeric_vals * 4) # remove the decimal places.

# barplot()
writeLines(paste0("When the values in raster cells are stored as integers as opposed to floats (with decimal points) they take up only ", 
       round(as.numeric(object.size(int_vals) / as.numeric(object.size(numeric_vals))),2),
        ' as many bytes.'))

rm(numeric_vals)
```

```{r Larger Data Set Integer vs Character, echo = F, comment="", warning =F, message = F}
int_vals <- as.integer(round(rnorm(n = 10000000, mean = 10, sd = 1), 0)) 

random_words <- OpenRepGrid::randomWords(n = max(int_vals) - min(int_vals))
lookup_numbers <- seq(from = min(int_vals), to = max(int_vals), by = 1)
character_vals <- random_words[match(int_vals, lookup_numbers)]

writeLines(paste0("When the values in raster cells are stored as integers as opposed to words they take up only ", 
       round(as.numeric(object.size(int_vals) / as.numeric(object.size(character_vals))),2),
        ' as many bytes.'))

rm(int_vals, random_words, lookup_numbers, character_vals)
```

Please note that our Raster in this scenario is *very* small, small enough we can wrap our brains around it with only minimal inspection.

Without knowing much about a raster (yet!) We can simulate some of these comparisons to give a clue as to why it contains values like they do. 

Rasters generally come in 8-bit signed (unsigned are not uncommon) integers. Pictures are huge amounts of data, these values help reduce them. 
```{r The size of Raster Components, message = F, warning = F, comment = "", out.width = "85%", fig.align="center", echo = F}

writeLines(paste0('The size of the our empty raster is ', as.numeric(object.size(empty_raster)/1000000), ' MB'))
size_rast_empty <- as.numeric(object.size(empty_raster))

rast_vals_char <- as.vector(as.character(dec_lakes_r_classified_f@data@values))
rast_vals_char <- ifelse(rast_vals_char == 0, 'Water', 'Terrestrial')
writeLines(paste0('The size of the data for our raster as a character vector is ', 
             as.numeric(object.size(rast_vals_char)/1000000), ' MB'))
size_vector_char <- as.numeric(object.size(rast_vals_char))

writeLines(paste0('The size of the data for our raster as a numeric (integer !) vector is ', 
             as.numeric(object.size(rast_vals_num)/1000000), ' MB'))
size_vector_num <- as.numeric(object.size(rast_vals_num))

writeLines(paste0('The size of the data for our raster in matrix form is ', 
             as.numeric(object.size(raster_matrix)/1000000), ' MB'))
size_rast_matr <- as.numeric(object.size(raster_matrix))

raster_dataframe <- as.data.frame(raster_matrix)
colnames(raster_dataframe) <- c(1:ncol(raster_dataframe)) 
writeLines(paste0('The size of the data for our raster in dataframe form is ', 
             as.numeric(object.size(raster_matrix)/1000000), ' MB'))
size_rast_df <- as.numeric(object.size(raster_dataframe))

writeLines(paste0('The size of our complete raster is ', 
             as.numeric(object.size(example_raster_dec)/1000000), ' MB'))
size_example_rast <- as.numeric(object.size(example_raster_dec))

sizes <- rbind(size_rast_empty, size_vector_num, size_vector_char, size_rast_matr, size_rast_df, size_example_rast)

sizes <- as.data.frame(cbind(rownames(sizes), sizes))
rownames(sizes) <- c(1:nrow(sizes))
colnames(sizes) <- c('Variable','Bytes')
sizes$Bytes <- as.numeric(sizes$Bytes)
sizes <- sizes[order(sizes$Bytes),]
sizes$Variable <- c('Spatial Raster', 'Vector (Int.)', 'Matrix (Int.)', 'Complete Raster', 'Dataframe (of Int.)', 'Vector (Char.)')

par(mar=c(5,7.5,2.5,5))
barplot(height = sizes$Bytes, names = sizes$Variable,  
        main="Size of Realized and Potential Raster Components",
        ylab = "",
        xlab="Bytes", 
        horiz = T, 
        las = 1, 
        density=c(50,50,50,50,50,50), 
        angle=c(45, 45, 90,45,45,135), 
        col=c("darkslategray4","darkslategray4", 'firebrick1',"darkslategray4", 'firebrick1', 'firebrick1'))

# writeRaster(example_raster_dec, 'Honey_lake_ex.tif')

rm(size_rast_empty, size_vector_char, size_vector_num, size_rast_matr, size_rast_df, size_example_rast, sizes)
```

# Vector Data in R

- **Vector Data Model** represents discrete features on the planet using geometries such as: points, lines, and polygons. 

## Simple Features - Standards

- Open Geospatial Consortium ISO 19125-1:2004: Currently adhered to in ESRI, used in GDAL.
- Features have *geometries* describing their locality on Earth, and properties described by *attributes.*
- If the geometry of a feature is a polygon, it is composed of points, connected by straight lines.
- Lines composing polygons cannot intersect

### Simple Features 1 - Attributes

- Attributes of the feature, theoretically devoid of spatial context.
- Described in text, numbers, stored in a data frame type object.

```{r Simple Features 1 - Attributes, echo = F}

attributes <- tibble(
  TAXON = c('Robinia pseudoacacia', 'Quercus alba'), 
  DBH = c(40, 32), 
  HEIGHT = c(24, 21)
)

knitr::kable(attributes)
```

### Simple Features 2 - Coordinates form a Point 

- all geometries are composed of points.
- points only require two coordinates, X & Y. 

- Y = Latitude (necessary), X = Longitude (necessary)
- Z = Elevation (somewhat uncommon)
- M = Time or Uncertainty of Measurement (rather uncommon)

```{r Simple Features 2 - Coordinates form a Point, echo = F, fig.align="center", out.width = "75%"}

ex <- data.frame(X = c(-7, -5, 0, 5, 9), Y = c(-8, 6, 0, -4, 5))
ex$Name <- paste0("c(", "x = ",  ex$X, ", y = ", ex$Y, ")")

ggplot(ex, aes(x = X, y = Y, label = Name), size = 5) +
  geom_point() +
  xlim(-10, 10) +
  ylim(-10, 10) +
  ggrepel::geom_label_repel(aes(label = Name),
                  box.padding   = 0.5, 
                  point.padding = 0.5,
                  segment.color = 'purple') 
  
rm(ex)
```

### Simple Features 3 - Points are/form a SF Geometry (sfg's)

- SFG is the spatial topology associated with a feature

- POINT - A true dimensionless 1 dimensional point
- LINESTRING - Sequence of points connected by strings.
- POLYGON - Sequence of points connected by strings, which close upon themselves. 
-- i.e. the first and last point of the polygon are the same.

```{r Simple Features 3 - Points are/form a SF Geometry (sfg), echo = F}
# Input example coordinates here and draw them in a facet grid via par
ex_point <- st_point(c(0,0))

ex_linestring <- st_linestring(
  rbind(
    c(-1.5,-2.5), c(-2,-2.25), c(-2.0,2.25), c(-1.5,2.5)
  )
)

ex_polygon <- st_polygon(
  list(
    rbind(
      c(0,-5), c(-2.5,-2.5), c(-2.5,2.5), 
      c(0,5),c(2.5,2.5), c(2.5, -2.5), 
      c(0,-5) # note we have to close the POLYGON, the last pt is same as the first!
    )
  )
)

ex_point_plot <- ggplot(ex_point) +
  geom_sf() +
  xlim(-5, 5) +
  ylim(-5, 5) +
  labs(title="Point") +
  theme(plot.title = element_text(hjust = 0.5))
ex_linestring_plot <- ggplot(ex_linestring) +
  geom_sf() +
  xlim(-5, 5) +
  ylim(-5, 5) +
  labs(title="Linestring") +
  theme(plot.title = element_text(hjust = 0.5))
ex_polygon_plot <- ggplot(ex_polygon) +
  geom_sf() +
  xlim(-5, 5) +
  ylim(-5, 5) +
  labs(title="Polygon") +
  theme(plot.title = element_text(hjust = 0.5))

cowplot::plot_grid(ex_point_plot, ex_linestring_plot, ex_polygon_plot, labels = NULL, ncol = 3)
```

### Simple Features 4 - A Geometry can be combined to form Geometries (sfg's)

- Two or more Points, and sets of Linestring, and polygons can be the geometries of a single feature
- Multi(POINT), multi(LINESTRING), multi(POLYGON) - Forming collections of geometries
- GEOMETRYCOLLECTION - A mixed set of these three or more geometries in the same geometry

```{r Simple Features 4 - Geometries can form Geometries (sfg), echo = F}

ex_multipoint <- st_multipoint(
  rbind(
    c(0,-4.0), c(-3,-2.5), c(-3, 2.5), 
    c(0, 4.0), c( 3, 2.5), c( 3,-2.5)
  )
)

ex_multilinestring <- st_multilinestring(
  list(
    rbind(c(-1.5,-2.5), c(-2,-2.25), c(-2.0,2.25), c(-1.5,2.5)),
    rbind(c( 1.5,-2.5), c( 2,-2.25), c( 2.0,2.25), c( 1.5,2.5))
  )
)
  
ex_multipolygon <- st_multipolygon(
  list(
    list(
      rbind(c(-3,-1), c(-3,1), c(-4,1), c(-4,-1), c(-3,-1))
    ), 
    list(
      rbind(c( 3,-1), c( 3,1), c( 4,1), c( 4,-1), c( 3,-1))
    )
  )
) 

ex_geometrycollection <- st_geometrycollection(list(ex_linestring, ex_polygon, 
                                                    ex_multipoint, ex_multilinestring, ex_multipolygon, ex_point))

ex_multipoint_plot <- ggplot(ex_multipoint) +
  geom_sf() +
  xlim(-5, 5) +
  ylim(-5, 5)  +
  labs(title="Multipoint") +
  theme(plot.title = element_text(hjust = 0.5))
ex_multilinestring_plot <- ggplot(ex_multilinestring) +
  geom_sf() +
  xlim(-5, 5) +
  ylim(-5, 5)  +
  labs(title="Multilinestring") +
  theme(plot.title = element_text(hjust = 0.5))
ex_multipolygon_plot <- ggplot(ex_multipolygon) +
  geom_sf() +
  xlim(-5, 5) +
  ylim(-5, 5)  +
  labs(title="Multipolygon") +
  theme(plot.title = element_text(hjust = 0.5))
ex_geometrycollection_plot <- ggplot(ex_geometrycollection) +
  geom_sf() +
  xlim(-5, 5) +
  ylim(-5, 5)  +
  labs(title="Geometycollection") +
  theme(plot.title = element_text(hjust = 0.5))

#ex_polygon[["data"]]$geometry
#ex_multilinestring[["data"]]$geometry

cowplot::plot_grid(ex_multipoint_plot, ex_multilinestring_plot, ex_multipolygon_plot, ex_geometrycollection_plot, labels = NULL, ncol = 4)

rm(ex_point, ex_linestring, ex_polygon, ex_multipoint, ex_multilinestring, ex_multipolygon, ex_multipoint_plot, ex_multilinestring_plot, ex_multipolygon_plot, ex_geometrycollection_plot, ex_point_plot, ex_geometrycollection, ex_linestring_plot, ex_polygon_plot)
```

### Simple Features 5 - Geometries and Spatial Information form an SF Collection (sfc)

- A list column of S3 type containing certain parameters regarding the Geometry/Geometries

- Coordinate Reference System ('crs')
- Precision ('precision')
- Bounding box ('bbox')
- Number Empty ('n_empty')

Wherein precision refers to the precision of the coordinates forming the geometries.
the bbox is a rectangle which includes all pairs of coordinates in the geometry.
N_empty, denotes whether the geometry is missing coordinates in a position.

### Simple Features 6 - Recapped. 

```{r Simple Features 6 Recapped,  echo = F, message = F, comment = ""}

attributes <- attributes %>% 
  mutate(LONG =  c(-87.676068, -87.673992)) %>% 
  mutate(LAT = c(42.056629, 42.057151)) %>% 
  st_as_sf(coords = c(x = 'LONG', y = 'LAT'), crs = 4326, remove = F)

knitr::kable(attributes)

st_precision(attributes) <- 2
attributes$geometry[1]
str(attributes$geometry[1])

rm(attributes)
```

- We now finally have *both* attributes and coordinates which are forming a point geometry.
- This is a Simple Feature. 

## sp

- Predecessor to the 'SF' R package
- Many spatial statistics programs still only take sp objects as input
- A good introduction to S4 objects; popular in new spatial packages too!

### sp - History

- Released in 2005 
- First package to hold all major vector types of geometries
- Unified Spatial class allowed for support in many spatial statistics packages
- Improved mapping of spatial objects

- Formed the centerpiece of spatial statistics in R for over a dozen years.

### sp - Spatial Classes for Topology

- SpatialPoints
- SpatialLines
- SpatialPolygons
- SpatialGrids

Similar in theory to the simple feature geometries we learned about...

### sp - Structures of The Spatial* Class - Topology Only

- Bounding box
- Coordinate Reference System
- ...Coordinates!

### sp - Attributes - DataFrame

- Attachment of attributes, in a data frame, to a Spatial topology can create:

- SpatialPointsDataFrame
- SpatialLinesDataFrame
- SpatialPolgonsDataFrame
- SpatialGridsDataFrame

- Each S*DF is accessed the same way e.g. SPDF@data[['col_name']]

We see here that SF contains all of the spatial information in a Simple Feature Collection which can be tidily tucked away in the geometry list column, in SP the analogue to the SFC is the object itself. 

SP is mostly geometry with a data slot, SF is mostly data frame with a geometry column. 

### sp Overview of a Spatial*DataFrame

```{r Creat some Spatial Classes, echo = F}
xc <- round(runif(15), 2)
yc <- round(runif(15, min = 0, max = 2), 2)
xy <- cbind(xc, yc)

sPoints <- SpatialPoints(xy)

df <- data.frame(z1 = round(5 + rnorm(15), 2), z2 = 20:34)
SPDF <- SpatialPointsDataFrame(sPoints, df)

plot(SPDF, col=SPDF@data[['z1']], pch = 25, xlim = c(0,1))
plot(gridlines(SPDF), add = TRUE, col = grey(.8))
text(labels(gridlines(SPDF)), col = grey(.7))
title("Example SP Plot")

rm(xc, yc, df, SPDF, xy, sPoints)
```

- Data frame is held in a different slot from the geometry and topology
- Data frame columns may be subset
- Data frame columns accessed via object@data[['colname']] indexing

### sp - Recapped.

- If you need to use spatial statistics, you will come across these objects.
- Don't sweat them **too** much; you can always convert from and to sf to run 
certain analyses

# Raster data in R

- Reminder: the Raster data Model is a way to represent (continuous) features on the planet using grids
- Excellent format for storing and sharing data
- Divides space into continuous grids
- Raster data sets are often distributed in *tiles*

```{r, out.width = "75%", fig.show='hold', echo = F, fig.align="center", fig.cap = "Western Plant Predictors. Note each cell is the extent of a single raster tile, each tile contains cells."}
knitr::include_graphics("pictures/Western_Plant_Predictors.png")
```

## Raster Components

- Bounding Coordinate(s)
- Cell Resolution (Size of cell)
- Dimensions (No of cells in rows and columns)
- Coordinate Reference System (CRS)

Note that both *cell sizes*, and the *resolution of the values* in cells can, within reason, be converted to finer and coarser resolution. We will discuss these types of calculations next class. 

### Example Raster 1 Create Frame

Rasters tend to confuse people. We are going to create our own example here before we talk about them much more.

Fairy shrimp live in bodies of water which dry out in late Spring, and refill in early Fall. We seek to determine where suitable habitat for fairy shrimp are in the Great Basin. In order to do so, we will use satellite imagery to detect valleys which fill with water in Fall, and dry out in late Spring.

```{r, out.width = "85%", fig.align="center", fig.show='hold', echo = F, fig.cap = "Suprise Valley by: John Glen"}
knitr::include_graphics('./pictures/SurpriseValley_JohnathonGlen_USGS.jpg')
```

```{r Create Empty Raster and Populate - 2 with output,  comment = "", warning = F}
empty_raster <- raster(
  
  # rasters have 4 bounding edges
  # Here we define each 'corner' of the raster'
    xmn = 697129.7, 
    xmx = 811775.7,
    ymn = 4388466,
    ymx = 4502382,
    
  # Here we set the number of cells 118*118
    nrows = 118, 
    ncols = 118,
    
    # we do NOT manually specify the cell size here.
    
    crs = "+proj=utm +zone=10 +datum=WGS84", 
    # set the rasters Coordinate Reference System
)
```

In the code above, we are going to define all four of the essential components of a raster. Clearly, we are defining three explicitly (Bounding Coordinates, Dimensions, CRS), and the remaining one implicitly (Cell resolution). 

```{r Create Empty Raster and Populate - 3 with output, fig.align="center", echo = F, comment = "", warning = F}

e <- extent(dec_lakes_r)
ext_rast <- st_bbox(dec_lakes_r)

# create a fishnet to emulate the idea of an empty raster ! :-)
grid <- st_make_grid(
  ext_rast,  
  n = c(118, 118),
  what = "polygons",
  square = TRUE,
  flat_topped = FALSE
  ) %>% 
  st_transform(32610)
# st_write(grid, 'Example_HoneyLake_Grid.shp')

ggplot(grid) +
  geom_sf(fill = NA) +
  coord_sf(datum = st_crs(grid)) +
  theme_classic() +
  labs(x = 'Easting', y = 'Northing')

rm(e)
```

We can imagine that the raster we are currently creating looks like this. A frame without content. We can see where the bounding coordinates are, 

```{r Create Empty Raster and Populate - 4 with output, echo = F, comment = "", warning = F}
rast_vals_num <- as.integer(as.vector(as.numeric(dec_lakes_r_classified_f@data@values)))
```

### Example Raster 2 Set Values

```{r Create Empty Raster and Populate - 5 with output,  comment = "", warning = F}
raster_matrix <- matrix(rast_vals_num, # # fill matrix with values, 
                       nrow = empty_raster@nrows, # create matrix same dimensions.
                       ncol = empty_raster@ncols, # create matrix same dimensions
#ensure filling of matrix goes from upper left to lower right.
                       byrow = T) 

raster_matrix[90:118,112:118] <- 1 # fix the clipping image at edge. 
```

```{r Create Empty Raster and Populate - 6 with output, echo = F, comment = "", warning = F}
fake_data <- matrix(c(0,1,1,0,1,0),
                    nrow = 6,
                    ncol = 8,
                    byrow=T)
knitr::kable(fake_data, caption = "Example Matrix showing values underlaying a raster layer.")
```


I think it is easiest to imagine that the values within a raster are in the shape of a matrix. Hence, using the code above we could take a vector of values, and bend them, so that each position within the vector matches up with the beginning of a new  row. 

```{r Create Empty Raster and Populate - 7 with output, comment = "", warning = F}
example_raster_dec <- setValues(empty_raster, raster_matrix)
```

### Example Raster 3 

```{r Create Empty Raster and Populate - 8 with output, fig.align="center",  comment = "", warning = F, echo = F}
raster_matrix <- raster::as.matrix(oct_lakes_r_classified_f)
raster_matrix[90:118,112:118] <- 1 

example_raster_oct <- setValues(empty_raster, raster_matrix)

tmap::tm_shape(example_raster_oct) +
tmap::tm_raster(style= "cat", title="Standing Water", 
                labels = c("0 = Open Water", "1 = Upland"), 
                palette = c("deepskyblue", "beige")) +
#tmap::tm_compass(type="arrow", position=c(.03, .87))+
#tmap::tm_scale_bar(position = c(0.15, .9), size=.8) +
tmap::tm_layout(legend.outside = TRUE)

resolution_of_raster(example_raster_dec)
cell_count(example_raster_dec)

rm(newproj, resolution_of_raster, cell_count, fake_data, ext_rast, grid, empty_raster, dec_lakes_r_classified_f, oct_lakes_r_classified_f, dec_lakes_r)
```

## Raster Package - in R! 

- Does not need to load all files into active memory at once
- Many functions based on functions in 'base' R. 

### Attributes

- Cells
- Values

### Raster Layer

A single raster .. do something cool here doofus. 

### Raster Brick

As I have mentioned rasters are often generated from satellite imagery; we will discuss rasters which are not developed this way next lecture. Historically most pictures are imaged via the use of three bands. These having spectral values of Red, Green, and Blue (RGB) associated with them. For example our .tif file, is composed of three bands. Note that a Rasterbrick is most often used for loading in these types of imaging data, which can then be processed to form a more typical 'raster' dataset.

```{r Raster Brick, echo=F, warning = F, message = F}
path <- './sentinel_imagery'
files.jpg <- list.files(path, ".jpg$")

dec_lakes_brick <- raster::brick(paste0(path,"/",files.jpg[4]))
dec_lakes_img <- terra::rast(paste0(path,"/",files.jpg[4]))

grayscale_colors <- gray.colors(150, start = 0.0, end = 1.0, gamma = 2.2, 
# [gamma] correction between how a digital 
# camera sees the world and how human eyes see it
                                alpha = NULL) 
# this code from NEON, see citations

par(mfrow=c(2,2))
plot(dec_lakes_brick, 1, col=grayscale_colors, main = "band 1 - Red")
plot(dec_lakes_brick, 2, col=grayscale_colors, main = "band 2 - Green")
plot(dec_lakes_brick, 3, col=grayscale_colors, main = "band 3 - Blue")
plotRGB(dec_lakes_img)

rm(dec_lakes_brick, grayscale_colors)
```

Rasters are often built from satellite imagery. Historically most pictures are split into three copies, each one having spectral values of Red, Green, and Blue (RGB) associated with them. For example our .tif file, is composed of three layers. Note that a Rasterbrick is most often used for loading in these types of data.

Bricks are very important for processing and classifying raw image data. While we have three bands here, nowadays LIDAR equipped with Hyperspectral sensors are likely to have many more bands up to a couple hundred depending on the application. 

One important technical point to note with the Rasterbrick is that each band of the brick loads from the same individual file, for example picture. And that  bands are not typically combined from different picture sources. 

Raster bands also do not need to be held in memor, allowing one to work through large amounts of them. 

### Raster Stack 

In general these are rasters which have been classified and we want to extract values from or run calculations with.  Now what is great about layers, is that we can do one big thing bricks cannot do, we can load in many layers from many files and create a stack of attributes we are interested in studying on the fly. 

```{r Raster Stack, echo=F, warning = F, message = F}
oct_lakes_img <- terra::rast(paste0(path,"/",files.jpg[2]))
my_cols <- c("Skyblue","Beige" )

par(mfrow= c(2,2))
plot(example_raster_oct, col=my_cols, main = "October")
plot(example_raster_dec, col=my_cols, main = "December")
terra::plotRGB(oct_lakes_img)
terra::plotRGB(dec_lakes_img)

rm(path, files.jpg, my_cols, oct_lakes_img, dec_lakes_img, example_raster_oct)
```

The main use of Raster Stacks is to hold layers of similar themes.

Two common examples:
1) Each raster layer in the stack is a variable from a different month, e.g. mean monthly temperature from January -> December (12 layers per stack)
2) Each raster layer in the stack is a variable of interest in an analysis, e.g. yearly mean temperature, mean precipitation, etc. from which we want to extract values.

Does not need be held in memory

## Terra

- Developed by the same team as the Raster Package
- Functionally virtually identical to Raster, but calculations run more quickly ! :-)
- Rasterbricks/layers no longer need specification, all objects are Spatstats ?
- Will supercede Raster, but see points 1 & 2. 

# Obect Orientated Programming in R

"Object-oriented programming (OOP) is a programming paradigm based on the concept of "objects", which can contain data and code: data in the form of fields (often known as attributes or properties), and code, in the form of procedures (often known as methods)." - from Wikipedia

To date we have largely focused on functional programming. That changes now.

```{r Object types - Create Types, echo = F}
dec_lakes_sf <- dec_lakes_v
dec_lakes_sp <- as(dec_lakes_v, 'Spatial')
dates_of_imaging <- dec_lakes_sf$Date
rm(dec_lakes_v)
```

R uses upwards of 25 types of objects. Many of these are highly specialized and we will not go into them, however it is necessary to elaborate on some of the differences between them. To date we have largely been using what may be called 'base' objects, i.e. objects which lack a 'class'. A class contains attributes which define certain parameters of the object, note that each attribute is based off of a 'base' object at some point.

## 10.1 Base Objects Reviewed

Some of the most common base objects are vectors, matrices, and lists.

```{r Object Types 1 make a vector, comment = ""}
rast_vals_char[1:3]
```

```{r Object Types 2 evaluate a vector, echo = F, comment=""}
writeLines(paste0('The first element of this vector is: ', rast_vals_char[1]))
writeLines(paste0('A vector is an object of type: ', otype(rast_vals_char)))
writeLines(paste0('This vector objects inhereits of class: ', s3_class(rast_vals_char)))
```

if we use the function 'otype' from the sloop package we can see that this object is a 'base' object and is in a class defined as character

```{r Object Types 3 make a matrix, comment = ""}
raster_matrix <- matrix(c(1,0,1,
                          0,1,1,
                          1,0,0), 
                        ncol = 3)
```

```{r Object Types 5 evaluate a matrix, echo = F, comment=""}
knitr::kable(raster_matrix[1:3,1:3])
writeLines(paste0('A matrix is an object of type: ', otype(raster_matrix)))
writeLines(paste0('A matrix inherits classes of: ', s3_class(raster_matrix)))
```


```{r Object Types 6 make list, echo = F, comment = ""}
raster_pieces_list <- list(Vector = rast_vals_char[1:3], 
                           Matrix = raster_matrix[1:3,1:3], 
                           Dataframe = raster_dataframe[1:3,1:3])
```

```{r Object Types 7 evaluate a list, echo = F, comment = ""}
writeLines(s3_class(raster_pieces_list))
writeLines('I made a list out of the last 2 objects and a dataframe:')
raster_pieces_list
writeLines(paste0('A list is an object of type: ', otype(raster_pieces_list)))
rm(raster_pieces_list, rast_vals_char, raster_matrix)
```

These base objects are more of less capable of just *storing* values. I.e. In a sense we can put whatever we want into a vector and it will work out - if we have mixed data types theywill be coerced to characters,  *but* we can do it.

```{r Object Types 8 Junk Vector, comment = ""}
junk <- c(1, 'A', 'alpahbet soup', '$')
print(junk)
```

```{r Object Types 9 clean junk, echo = F}
rm(junk)
```

## 'Introduction' to S3 Objects

```{r Object Types POSIXct 1, echo = F, comment = ""}
writeLines(paste0('This is an example of a POSIXct time: ', dates_of_imaging[1], ', to me it just looks like a character vector'))
```
Let's take a look at our vector of POSIXct time zones, which superficially to me (an human) look like numbers separated by dashes. 

```{r Object Types POSIXct 2, echo = F, comment = ""}
attributes(dates_of_imaging)
```

We see that two attributes are stored in that object. The first is the timezone, which is defined elsewhere in R (and I believe is inherited by R from other systems), but is notated within this object. Critically, We also have the formal 'class' definition of a POSIXct format.

```{r Object Types POSIXct 3, echo = F, comment = ""}
writeLines(paste0("The amount of seconds since 1970 and ", dates_of_imaging[1], " is: ", as.numeric(dates_of_imaging[1])))
```

POSIXct dates are all actually treated in R as the amount of seconds between an arbitrary date e.g. January 1st 1970, and the date of observation; so R is really keeping dates in a numeric format - but is hiding this from us! And converting the values into a more human friendly format more or less for display purposes only.

This is a new level of functionality that we have not directly considered yet this quarter. As mentioned we have used objects much like book pages. Now we see that certain objects, are able to refer to themselves to perform, for example, calculations and conversions.

```{r Object Types POSIXct 4, echo = F, comment = ""}
writeLines(paste0('A POSIXct is an object of type: ', otype(dates_of_imaging)))
rm(dates_of_imaging)
```

Objects with the capability to store values in fields, and perform procedures upon themselves form the basis of Object Orientated Programming. In R we have two main OOP classes, S3 and S4. In general objects of both of these classes are *'large'*, however this is not always the case. 

Another S3 object which superficially looks like a vector is an 'Units' object.

When we define a units object, we can simply supply a number for value, and a unit of measurement. 
```{r Object Types Units 1, comment = ""}
fifty_meters <- units::set_units(50, meter)
print(fifty_meters)
```

These objects are capable of performing procedures on themselves, such as converting between meters and yards.
```{r Object Types Units 2, comment = ""}
units(fifty_meters) <- units::make_units(yards)
print(fifty_meters)
```

```{r Object Types Units 3, echo = F, comment = ""}
writeLines(paste0('A Units is an object of type: ', otype(fifty_meters)))
writeLines(paste0('It is its own units class: ', s3_class(fifty_meters)))
attributes(fifty_meters)

rm(fifty_meters)
```

```{r Object Types 1 - Data Frame, echo = F, comment = ""}
raster_dataframe <- raster_dataframe[1:10, 1:10]
colnames(raster_dataframe) <- sample(letters[1:11], size = ncol(raster_dataframe))
rownames(raster_dataframe) <- sample(LETTERS[14:26], size = nrow(raster_dataframe))
```

A more shocking S3 object is the data frame

```{r Object Types 2 - Data Frame, echo = F, comment = ""}
writeLines(otype(raster_dataframe))
attributes(raster_dataframe)

rm(raster_dataframe)
```

We see that of the non-base objects, the most common object is S3. Actually, surprise surprise the amazing data frame has been hiding out as an S3 object this whole time! You may have actually seen an error message indicating this at some point...  So if we look at the attributes of a data frame we see that we have both row and columns names, and we also have a formal definition of the class being a data frame, which in part consists of code demanding that our data frame be rectangular in nature. 

Finally we turn our attention to one slightly more complex S3 object.

### Simple Features

The incredibly popular Simple Features 'SF' package actually stores all it's features in S3 object. Given that a data frame is an S3 object, this is a necessity - but there are some big jumps under the hood. I bet, even more so than these objects being 'accessible' via tidyverse syntax the simplicity of the S3 object compared to S4 sp objects is what spurred there popularity

```{r Object Types - Tibble Simple Feature 1, echo = F, comment = ""}
writeLines(paste0('A simple feature is an object of type: ', otype(dec_lakes_sf)))
```

What is really neat about tibbles, and I am not sure if you all recall is that while they just look like a data frame they are capable of holding a list in a column, hence a 'list column'.

```{r Object Types - Tibble Simple Feature 2, echo = F, comment = ""}
knitr::kable(head(iris))
```

For example we can take the four columns of the Iris dataset which contain the measurement variables, and reduce them to two thematic list columns using the 'nest' function. 

```{r Object Types - Tibble Simple Feature 3, comment = ""}
iris <- iris %>% 
  nest(petal = starts_with("Petal"), 
       sepal = starts_with("Sepal")
       ) 

iris 
# Check the first row of the second column
head(iris[[2]][[1]]) 
# see the structure of the first row of the petal column
str(iris$petal[[1]])

```

If we take a close look at the first for of the second column, that for *I. setosa*, we see all of the short and narrow petal measurements we are familiar with for this species. 

In this example we see that each element in 'petal' contains a list of its own, each of which has a data frame with a column storing *both* the Petal Length and Petal Width values. Each row of each list column (petal & sepal) we see in this tibble is like this.


So what the developers of SF did is to create an S3 object which can hold all of the spatial information in a list column - without you really realizing this information is there. 

```{r Object Types - Tibble Simple Feature 4, echo = F, comment = ""}
print(s3_class(dec_lakes_sf))
knitr::kable(head(dec_lakes_sf[,c(2:3,6)]))
attributes(dec_lakes_sf$geometry)

rm(iris, dec_lakes_sf)
```

This is output is understandably a little much, but these are *all* of the attributes of a Simple Feature Collection which is hidden in the geometry column of a simple feature. Clever right?

## Introduction to S4 Objects

Now S3 objects, are somewhat lax. However there is an S4 object which is a little bit more complex.

Examples of S4 objects include the lovely Raster, and Spatial*(e.g. Points, Polygons, Dataframes...) objects. I find that lists, and S4 objects terrify virtually all of our students each year. Myself included, and in fact I am still slightly spooked by them. While I cannot teach you all how exactly to deal with them, I can teach you all of use them day to day. 

S4 objects are not lax, they are the stricter implementation of S3 objects. The classes which compose S4 objects are incredibly well defined, and they are designed for very specific use cases. This may at times make them obnoxious to work with, when you need to build or modify values in them, but thye are worth the pain. 

```{r Object Types - SpatialPolygonsDataFrame 1, comment = ""}
writeLines(otype(dec_lakes_sp))
writeLines(s3_class(dec_lakes_sp))
```

### Spatial* Objects

Just like as in S3 objects in S4 objects the classes follow certain schema. Note we use a SpatialPolygonsDataFrame as our example here.

In addition to their more strict definitions of classes, S4 objects have another feature which S3 objects lack - Slots. Slots superficially resemble lists in the viewer of RStudio, i.e. they have nested components, but are really their own distinct entities. A SpatialPolygonsDataFrame contains 4 slots, each of these contains a type of data. Note that each slot is accessed using an '@' (still pronounced: 'at') symbol. 

```{r  Object Types - SpatialPolygonsDataFrame 2, comment = ""}
dec_lakes_sp@plotOrder
otype(dec_lakes_sp@plotOrder)
writeLines(s3_class(dec_lakes_sp@plotOrder))
```

Here we access the contents of a slot named 'plotOrder'. We see that this slot simply contains an integer vector. What this vector specifies is the order in which the polygons in this object should be plotted if and when used for making maps. While this information is stored simply as an object of the class 'base', other parts of the SpatialPolygonsDataFrame know how to perform operations with this information.

```{r  Object Types - SpatialPolygonsDataFrame 3, comment = ""}
head(dec_lakes_sp@data)[,c(1:3,5)]
```

We can see that the 'DataFrame' portion of the SpatialPolygonsDataFrame has actually been relegated to it's own slot as well.

```{r Object Types - SpatialPolygonsDataFrame 4, comment = ""}
attributes(dec_lakes_sp@data)
otype(dec_lakes_sp@data)
writeLines(s3_class(dec_lakes_sp@data))
```

While the two slots above, @plotOrder & @data, contain relatively simple objects (base and S3 respectively). The remaining two slots, which are both S4 classes contain all of the spatial information. 

```{r Object Types - SpatialPolygonsDataFrame 5, echo = F, comment = ""}
writeLines(s3_class(dec_lakes_sp@proj4string))
otype(dec_lakes_sp@proj4string)
attributes(dec_lakes_sp@proj4string)
```

The first of the S4 slots is the proj4string (Proj is an awesome open source library for performing conversions between projections), which contains a class "CRS" which defines the Coordinate Reference System of this SpatialPolygonsDataFrame. Hence any time you modify the CRS of a SPDF, you are interacting with this slot.

The final, and most complex of the two S4 slots in a SpatialPolygonsDataFrame is the Polygons slot. This is where the coordintaes, and topological information, fo every single polygon is stored. 
```{r Object Types - SpatialPolygonsDataFrame 6, echo = F, comment = ""}
writeLines(otype(dec_lakes_sp@polygons[[9]]))
attributes(dec_lakes_sp@polygons[[9]]) #  S4 object in this slot, contains all coordinates.

rm(dec_lakes_sp)
```

Here we are looking at the smallest of the polygons in our SPDF (see the plotOrder?). These data are replicated appropriately for each of the other polygons in this object. 

While this S3 object is more complex, we can see how the components held in multiple slots are able to work together to perform operations using the data held in disparate fields throughout the object.

### Raster Objects

Finally we have the Raster Layer which is a rather large and complex S4 unit, composed of 12 main S4 slots... Each of these then having from 1 to 13 slots (these second slots quite small, and not uncommonly consisting of a single value). 

```{r Object Types Raster Layer 1, echo = F, comment = ""}
str(example_raster_dec)
```

Raster Layers are large enough that we unfortunately cannot go into it much during class, but I do encourage the curious you to investigate it on your own. Do keep in mind that it has a slot of 'CRS' which we just saw in our SP object, and it also has a slot of 'extent' which we defined ourselves earlier. 

```{r Object Types Raster Layer 2, echo = F, comment = ""}
writeLines(paste0('Class: ', otype(example_raster_dec)))
writeLines(paste0('Class type: ', s3_class(example_raster_dec)))

writeLines(s3_class(example_raster_dec@data))
# attributes(example_raster_dec@data)
writeLines(s3_class(example_raster_dec@data@values))
```

If we look at our data slot we see that we have an 'integer numeric' type - which is typically how a raster is loaded. I will concede up to this point I said to think about a raster as matrix, but we see ours is actually loaded with an integer. Remember that in R both matrices and data frames are vectors. Remember a main difference between a vector and a matrix, is that a matrix has dimensions, i.e. it knows how many values need to be in each row. While these data are not explicit here, they can be found in another slot. 

```{r Object Types - Clean Environment, echo = F}
rm(rast_vals_num, example_raster_dec)
```

# Object Orientated Programming Bonus: Make our own S3 and s4 objects.

So we approached S3 and S4 objects from a very top down approach there, we looked at those constructed by others. But we can also create our own objects, so we can look at these from the bottom up. 

## Create a simple S3 object

Maybe none of you have noticed yet but you will oon enough; your TA has some traits in common with say Luna Lovegood, and finds it hard to make it to meetings and things. Here we makes a course object which he can save into his R environment so he can just click on it to remind him when he is suppose to show up for class. 

```{r Create an S3 object 1, message = F, warning = F, comment = ""}

course <- list(
  name = c("Lecture", "Lecture", "Laboratory", "Laboratory"),
  wing = c('L', 'L','M','L'),
  room = c(170, 170, 166, 62),
  day  = c('T', 'TH', 'F', 'F'),
  time = c('3:30-4:50', '3:30-4:50', '12:00-12:50', '2:00-3:50')
)

writeLines(sloop::s3_class(course)) # we have only made a list so far 
writeLines(sloop::otype(course))

class(course) <- "Class_times" # by setting a class attribute we have 
# created an S3 object

writeLines(sloop::s3_class(course))
sloop::otype(course)

rm(course)
```
We see that the above object is honestly, just a list that we arbitrarily made an S3 object. That is more or less what it takes to become an S3 object, us just saying hey 'this is a class' !

But we can do things with S3 objects which make them useful to construct. For example, we can add quality assurance checks to our objects.

## Create a more complex S3 object

Your TA made a very poor first list of places he had to be for class, and ended up wandering around tech lost for an hour. He decided to make a slightly more robust Sw object so this did not happen again.

```{r  Create an S3 object 2, warning = F, comment = ""}
course <- function(n, w, r, d, t){
  
  values <- list(name = n, 
                 wing = w, 
                 room = r, 
                 day = d, 
                 time = t)
    
  '%notin%' <- Negate('%in%')
  type <- c('Lecture', 'Laboratory', 'Seminar')
  tech_letters <- LETTERS[1:13]
  days <- c('M', 'T', 'W', 'TH', 'F', 'S', 'SU')
  
  if(any(w %notin% tech_letters)) stop("This wing is not valid")
  if(any(d %notin% days)) stop("This day is not valid")
  if(any(n %notin% type)) stop("This course type is not valid")
  
  attr(values, "class") <- "Course"
  return(values)
  
}
```

```{r  Create an S3 object 3, warning = F, comment = ""}
course_success <- course(c("Lecture", "Lecture", "Laboratory", "Laboratory"),  
                         c('L', 'L','M','L'),
                         c(170,170,166,62), 
                         c('T','TH','F','F'), 
                         c('3:30-4:50','3:30-4:50', '12:00-12:50', '2:00-3:50')
                         )
```

Here we see that an object of the S3 class can be much more than merely a collection of attributes. An S3 object can perform quality assurance steps to ensure the data comply to certain types, and that values are in appropriate units etc. 

If the data are these thoroughly defined, we then see this opens the opportunity for an S3 object to act upon other parts of itself. While in the example above we put in values which match the acceptable criteria of the class we have defined, in the example below will violate the standards of our S3 Object.  

```{r Create an S3 object 4, warning = F, eval = F}
course_fail <- course("Lecture",  
            'Z', # THIS IS NOT DEFINED
            213, 'TH', '2:00-3:50')
```

simulated output (R does not like errors, intentional or not):

"Error in course("Lecture", "Z", 213, "TH", "2:00-3:50") : This wing is not valid"

In the above example, if you input the wrong Wing in Tech, or the wrong day of week abbreviation, this class will angrily let you know and refuse to take your input. I assume this error can be relegated to a warning - but we will not get into those aspects of coding in this class. 

One, possible, draw back of an s3 object is that it is relatively lax. 

```{r Create an S3 object 5, warning = F, echo = F}
rm(course, course_success, course_fail)
```

## Create a simple S4 object

The s4 object is not lax. Here we define the data type which each of these slots will accept. If the value you try to put in does not match, the object will not be created.
```{r Create an S4 object, message = F, warning = F, comment = ""}
setClass("Office_Hours", 
         slots=
           list(
            Instructor="character",
            Wing= "character",
            Number="numeric",
            Days="character",
            Time="numeric",
            Smartroom="logical",
            Windows="logical"
            )
         )
```

- Seven slot object, each slot with a specified data type. 
- Will only input to each column of the correct data type.

```{r Populate an S4 object, message = F, warning = F, comment = ""}
s4_ob_office_hours <- new("Office_Hours", 
  Instructor = c('Benkendorf','Scholl','Benkendorf','Scholl'),
  Wing = c('F', 'F', 'G', 'B'),
  Number = c(380, 380, 278, 138),
  Days = c("M", "W", 'T', 'F'),
  Time = c(8, 11, 9, 3),
  Smartroom = c(TRUE, F, T, F),
  Windows = c(FALSE, T, T, F)
)
```

In it's simplest form an s4 object may be constructed via the setClass function. While this object is able to regulate the data types which are entered to each column, it cannot do much more. 

## Create a more complex S4 object

An S4 object can have validity functions, which basically ensures the data you put into it is appropriate. 
```{r Create a more complex S4 object, message = F, warning = F, comment = ""}

office_hrs <- setClass("Office_Hours", 
         
         slots=c(
           Instructor="character",
           Wing= "character",
           Number="numeric",
           Days="character",
           Time="numeric",
           Smartroom="logical",
           Windows="logical"
           ),
         
        validity=function(object){
          
            '%notin%' <- Negate('%in%')
            tech_letters <- LETTERS[14:26]
            days <- c('M', 'T', 'W', 'TH', 'F', 'S', 'SU')
            instructors <- c('Scholl', 'Benkendorf')
                
            if(any(object@Instructor != instructors))stop("This Instructor is not valid")
            if(any(object@Wing %in% tech_letters))stop("This Wing is not valid")
            if(any(object@Days %notin% days)) stop("This Day is not valid")
  }
)
```

- Mandates the appropriate data type is entered
- Checks that the 'Wing' we enter exists in the Tech Building
- Ensures that a valid Instructor is entered
- Ensures that the appropriate abbreviation for a day is entered.
- Object clearly capable of performing procedures on itself. 

```{r Populate a more complex S4 object, message = F, warning = F, comment = ""}

s4_ob_office_hours <- office_hrs( 
  Instructor = c('Scholl', 'Benkendorf', 'Scholl', 'Benkendorf'),
  Wing = c('A', 'F', 'B', 'B'),
  Number = c(123, 412, 278, 138),
  Days = c("M", "W", 'T', 'F'),
  Time = c(8, 11, 9, 3),
  Smartroom = c(TRUE, F, T, F),
  Windows = c(FALSE, T, T, F)
)

otype(s4_ob_office_hours)
s3_class(s4_ob_office_hours)

rm(s4_ob_office_hours, office_hrs)
```

- Easy examples, but we could also script in conversion functions like with the ealier Units and POSIX S3 objects.
- S3/S4 objects can have a lot going on 'under the hood'
- At their heart, they are performing operations on themselves. 

You will realize in short time, that the biggest hurdle to dealing with spatial data in R is how complex some of the structures may be. But I guarantee you all have seen more of the intricate workings of these objects than the vast majority of folks which utilize them. Just remember, to appease the validity functions and you will be fine. 

```{rCreate an S4 object 3, message = F, echo = F, warning = F, comment = ""}
rm(s4_ob_office_hours, office_hrs)
```

# Assignments for the Duration of the Spatial Data Science Module:

**For next Lab: **

*Please* install these packages (if you have not done so already):
```{r For Lab and Lecture, eval = F}
install.packages("sf", "raster", "terra", "sp", "tmap", "leaflet", "ggmap")
# optional packages for using parallel processing at a step
# (in our example it won't actually speed up the analyses 
# they actually may slow them down!)
install.packages('snow','parallel')
```

Download the labs .R script from the course website. 

If you are interested in how Drone/Lidar data are collected please check out the 'RMBL Spatial Data Science Webinar Series':

- https://github.com/ikb-rmbl/SpatialDataScienceWebinars2020 
- Collecting UAS Data (Video): https://youtu.be/Pq8btEZRCvM (1.25 hours)

**For next Lecture:**
Assigned Reading: Chapter 3 of Spatial Data Science

**Future Bonus SDS Office Hours**
Wednesday Night at 5:00 - 6:00. 

**Notes on this Lab**
My lecture notes are in the R script I used to generate all of the novel figures for this presentation. Likewise this presentation is an .HTML file and can be launched from your computer (it was rendered directly from R using the script). 

# Works Cited

Krystalli, A. https://annakrystalli.me/intro-r-gis/gis.html Accessed 01.20.2022

Advanced R. Wickham, H.  https://adv-r.hadley.nz/index.html Accessed 01.09.2022

https://geocompr.robinlovelace.net/spatial-class.html Accessed 01.09.2022

Hijman, R. 05.12.2019 'The raster Package'

https://www.datamentor.io/r-programming/s3-class/ Accessed 01.18.2022

https://rspatial.org/raster/RasterPackage.pdf Accessed 01.09.2022

https://www.neonscience.org/resources/learning-hub/tutorials/dc-multiband-rasters-r Accessed 01.19.2022

Pebesma, E.J., R.S. Bivand, 2005. Classes and methods for spatial data in R. R News 5 (2).

Pebesma, E. https://r-spatial.github.io/sf/articles/sf1.html Accessed 01.10.2022

https://proj.org/operations/conversions/geoc.html Accessed 01.20.2022.

https://rspatial.org/raster/spatial/8-rastermanip.html Accessed 01.11.2022

https://en.wikipedia.org/wiki/Open_Source_Geospatial_Foundation Accessed 01.09.2022

https://cran.r-project.org/web/packages/vctrs/vignettes/s3-vector.html Accessed 01.14.2022

https://en.wikipedia.org/wiki/Object-oriented_programming Accessed 01.19.2022

NOAA. What is geodesy? National Ocean Service website, https://oceanservice.noaa.gov/facts/geodesy.html, 1/25/17.

Geocomputation with R. Lovelace, R., Nowosad, J., Muenchow, J. 2022-01-25.

